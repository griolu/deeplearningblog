{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-01-29-Reflections.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-BW6Uxp2hMY"
      },
      "source": [
        "# Reflection on Trigger Me fast.ai and Future Plans\r\n",
        "> Good learning experience from yesterday's disappointment.\r\n",
        "\r\n",
        "- toc: true \r\n",
        "- badges: true\r\n",
        "- comments: true\r\n",
        "- categories: [jupyter]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clKqv_Bq6Qyv"
      },
      "source": [
        "## What I learned\r\n",
        "So, yesterday's model was not a very well-made model. It seems that my objective didn't coincide with the way I trained it. Rather, its objective is to differentiate between male vs. female, given an image of a Korean. When I gave it any image, it had a difficult time determining whether it was a Korean; for example, if I gave it an image of a bear, it would call it a Korean man with 90% probability; or, when I gave an image of a Black man, it predicted a Korean man with 99.95% probability. The model was trained on categories, so it would try to predict one of the categories. My thought was to have it learn the facial features of Koreans, but it seems like it just learned how to differentiate between genders and age of (most) human faces. The 80% probability threshold that I made may have also been too high. It wasn't able to detect if there was an Asian when I gave it another image of Michael Reeves or LilyPichu. It could also be that the data was quite biased to certain types of Korean faces. \r\n",
        "![](https://cdn.discordapp.com/attachments/404451746145107969/804477340650438676/unknown.png \"Black man getting 0.9995 probability that he's an East Asian man.\")\r\n",
        "\r\n",
        "## What I'll do\r\n",
        "I'll create a better model with the objective to predict on categories, not whether something is *x*. In other words, the plan of creating a model that can detect a cat or squirrel is scrapped. Tomorrow, I'll instead create a model that can tell you who the OfflineTV member is, given an image of an OfflineTV member. I can do a similar thing with yesterday, though, where if the probability is less than 50%, we can say they're not an OfflineTV member. One of the main issues would be getting the data because searching up \"DisguisedToast face\" may provide the same image of DisguisedToast's face reveal. Likewise, \"LilyPichu\" might just lead to images of her logo. But, we'll see how it goes. If all goes south, we can create a simpler model that can differentiate between a mouse and a keyboard :).  \r\n",
        "![](https://i.ytimg.com/vi/I_zUtqT6kWQ/hqdefault.jpg \"DisguisedToast's face reveal\")"
      ]
    }
  ]
}
